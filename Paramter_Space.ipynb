{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Date_Julian</th>\n",
       "      <th>DMP_NoWater</th>\n",
       "      <th>Surface_Irradiance</th>\n",
       "      <th>Below_Ice_Irradiance</th>\n",
       "      <th>Surface_Temp_C</th>\n",
       "      <th>Surface_Temp_K</th>\n",
       "      <th>Joules</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Days_Above_24hr_Frz_AirTemp</th>\n",
       "      <th>Hrs_Above_Frz_Ice_Since_Jun1</th>\n",
       "      <th>Cum_Surface_Irradiance_SinceJun1</th>\n",
       "      <th>Cum_Sub-Surface_Irradiance_SinceJun1</th>\n",
       "      <th>Source</th>\n",
       "      <th>Split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-Jun</td>\n",
       "      <td>152</td>\n",
       "      <td>0.001</td>\n",
       "      <td>62300000.0</td>\n",
       "      <td>814000.0</td>\n",
       "      <td>1.689247</td>\n",
       "      <td>274.839247</td>\n",
       "      <td>3.790000e-21</td>\n",
       "      <td>72.844081</td>\n",
       "      <td>-166.537644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.070000e+09</td>\n",
       "      <td>84000000.0</td>\n",
       "      <td>Buoy7</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4-Jun</td>\n",
       "      <td>155</td>\n",
       "      <td>0.005</td>\n",
       "      <td>65000000.0</td>\n",
       "      <td>1840000.0</td>\n",
       "      <td>3.694515</td>\n",
       "      <td>276.844515</td>\n",
       "      <td>3.820000e-21</td>\n",
       "      <td>73.037055</td>\n",
       "      <td>-166.767810</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24</td>\n",
       "      <td>2.260000e+09</td>\n",
       "      <td>88300000.0</td>\n",
       "      <td>Buoy7</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5-Jun</td>\n",
       "      <td>156</td>\n",
       "      <td>0.013</td>\n",
       "      <td>64300000.0</td>\n",
       "      <td>1450000.0</td>\n",
       "      <td>4.947612</td>\n",
       "      <td>278.097612</td>\n",
       "      <td>3.840000e-21</td>\n",
       "      <td>72.844835</td>\n",
       "      <td>-163.319440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>2.460000e+09</td>\n",
       "      <td>45700000.0</td>\n",
       "      <td>Buoy8</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5-Jun</td>\n",
       "      <td>156</td>\n",
       "      <td>0.017</td>\n",
       "      <td>58700000.0</td>\n",
       "      <td>2520000.0</td>\n",
       "      <td>5.777930</td>\n",
       "      <td>278.927930</td>\n",
       "      <td>3.850000e-21</td>\n",
       "      <td>73.055408</td>\n",
       "      <td>-166.908423</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41</td>\n",
       "      <td>2.320000e+09</td>\n",
       "      <td>90800000.0</td>\n",
       "      <td>Buoy7</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-Jun</td>\n",
       "      <td>161</td>\n",
       "      <td>0.020</td>\n",
       "      <td>133000000.0</td>\n",
       "      <td>349000.0</td>\n",
       "      <td>-1.576667</td>\n",
       "      <td>271.573333</td>\n",
       "      <td>3.750000e-21</td>\n",
       "      <td>76.865833</td>\n",
       "      <td>-165.986000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.020000e+09</td>\n",
       "      <td>4410000.0</td>\n",
       "      <td>SHEBA</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date  Date_Julian  DMP_NoWater  Surface_Irradiance  Below_Ice_Irradiance  \\\n",
       "0   1-Jun          152        0.001          62300000.0              814000.0   \n",
       "1   4-Jun          155        0.005          65000000.0             1840000.0   \n",
       "2   5-Jun          156        0.013          64300000.0             1450000.0   \n",
       "3   5-Jun          156        0.017          58700000.0             2520000.0   \n",
       "4  10-Jun          161        0.020         133000000.0              349000.0   \n",
       "\n",
       "   Surface_Temp_C  Surface_Temp_K        Joules        Lat         Lon  \\\n",
       "0        1.689247      274.839247  3.790000e-21  72.844081 -166.537644   \n",
       "1        3.694515      276.844515  3.820000e-21  73.037055 -166.767810   \n",
       "2        4.947612      278.097612  3.840000e-21  72.844835 -163.319440   \n",
       "3        5.777930      278.927930  3.850000e-21  73.055408 -166.908423   \n",
       "4       -1.576667      271.573333  3.750000e-21  76.865833 -165.986000   \n",
       "\n",
       "   Days_Above_24hr_Frz_AirTemp  Hrs_Above_Frz_Ice_Since_Jun1  \\\n",
       "0                          0.0                             0   \n",
       "1                          2.0                            24   \n",
       "2                          1.0                            60   \n",
       "3                          3.0                            41   \n",
       "4                          0.0                             0   \n",
       "\n",
       "   Cum_Surface_Irradiance_SinceJun1  Cum_Sub-Surface_Irradiance_SinceJun1  \\\n",
       "0                      2.070000e+09                            84000000.0   \n",
       "1                      2.260000e+09                            88300000.0   \n",
       "2                      2.460000e+09                            45700000.0   \n",
       "3                      2.320000e+09                            90800000.0   \n",
       "4                      6.020000e+09                             4410000.0   \n",
       "\n",
       "  Source  Split  \n",
       "0  Buoy7  Train  \n",
       "1  Buoy7   Test  \n",
       "2  Buoy8  Train  \n",
       "3  Buoy7  Train  \n",
       "4  SHEBA  Train  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "data = pd.read_csv('C:/Users/Austin/Desktop/OEAS895_Clayton/Project/Data/model_input.csv') #read in data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 4)\n",
      "(14, 4)\n",
      "(8,)\n",
      "(14,)\n"
     ]
    }
   ],
   "source": [
    "#define variables for machine learning\n",
    "test=data[~data.Split.str.contains(\"Train\")] #create test data\n",
    "train=data[~data.Split.str.contains(\"Test\")] #create train data\n",
    "\n",
    "x_train=train[['Hrs_Above_Frz_Ice_Since_Jun1','Lat','Lon','Cum_Surface_Irradiance_SinceJun1']] #slight increase in r^2 (0.02)\n",
    "x_test=test[['Hrs_Above_Frz_Ice_Since_Jun1','Lat','Lon','Cum_Surface_Irradiance_SinceJun1']]\n",
    "\n",
    "#set target variable\n",
    "y_train=train[['DMP_NoWater']]\n",
    "y_test=test[['DMP_NoWater']]\n",
    "y_train=np.ravel(y_train)\n",
    "y_test=np.ravel(y_test)\n",
    "y=data.DMP_NoWater\n",
    "\n",
    "print(np.shape(x_test))\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(y_test))\n",
    "print(np.shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Austin\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Austin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n",
      "C:\\Users\\Austin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20, 30, 40, 50, 60, 70, 80, 90, 100)\n",
      "(1, 2, 3)\n",
      "[1]\n",
      "1 10 -2.4936407528872784 0.029725587757804643\n",
      "1 20 -0.30272669495767746 0.01108422972894279\n",
      "1 30 0.10319839052018165 0.007630422481733887\n",
      "1 40 0.8838559421676191 0.0009882099013159098\n",
      "1 50 0.7112974483724246 0.0024564211495458556\n",
      "1 60 0.31596898293336606 0.0058200672207268135\n",
      "1 70 0.9023011138002034 0.0008312694466858726\n",
      "1 80 0.8187647221554143 0.0015420375297394411\n",
      "1 90 0.7798646827489806 0.0018730179072159667\n",
      "1 100 0.8031378882705011 0.0016749982016799453\n",
      "[1 1]\n",
      "2 10 -0.6795871619048648 0.014290741123518138\n",
      "2 20 0.5063991140039421 0.004199795425983615\n",
      "2 30 0.5567716930583428 0.003771201124170794\n",
      "2 40 0.7954603824312769 0.0017403221401519552\n",
      "2 50 0.6790851823376747 0.0027304987117858694\n",
      "2 60 0.783971516021297 0.0018380749804877325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Austin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:302: RuntimeWarning: overflow encountered in byte_scalars\n",
      "  init_bound = np.sqrt(factor / (fan_in + fan_out))\n",
      "C:\\Users\\Austin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:302: RuntimeWarning: invalid value encountered in sqrt\n",
      "  init_bound = np.sqrt(factor / (fan_in + fan_out))\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "Range exceeds valid bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f19aaad4d3ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLPRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#1000 iterations wasn't enough to optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Austin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m         \"\"\"\n\u001b[1;32m--> 618\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Austin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    340\u001b[0m                                            incremental):\n\u001b[0;32m    341\u001b[0m             \u001b[1;31m# First time training the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_units\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;31m# lbfgs does not support mini-batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Austin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, y, layer_units)\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             coef_init, intercept_init = self._init_coef(layer_units[i],\n\u001b[1;32m--> 283\u001b[1;33m                                                         layer_units[i + 1])\n\u001b[0m\u001b[0;32m    284\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercepts_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Austin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36m_init_coef\u001b[1;34m(self, fan_in, fan_out)\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;31m# Generate weights and bias:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         coef_init = self._random_state.uniform(-init_bound, init_bound,\n\u001b[1;32m--> 306\u001b[1;33m                                                (fan_in, fan_out))\n\u001b[0m\u001b[0;32m    307\u001b[0m         intercept_init = self._random_state.uniform(-init_bound, init_bound,\n\u001b[0;32m    308\u001b[0m                                                     fan_out)\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.uniform\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOverflowError\u001b[0m: Range exceeds valid bounds"
     ]
    }
   ],
   "source": [
    "##EXPLORE PARAMETER SPACE\n",
    "\n",
    "#import sklearn packages\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "#create empty lists\n",
    "scores=[]\n",
    "scores_list=[]\n",
    "results=[]\n",
    "\n",
    "#create a range of numbers of nodes to be tested (10-100, jumping by 10's)\n",
    "n = tuple(range(10, 101, 10))\n",
    "print(n)\n",
    "#create a range of numbers of layers to be tested (1-3)\n",
    "l = tuple(range(1,4,1))\n",
    "print(l)\n",
    "\n",
    "#build a nested loop to loop through both various numbers of layers and nodes\n",
    "for l in l:\n",
    "    layers = np.ones(l, dtype=np.int8) #create an array of ones that loops with l\n",
    "    print(layers)\n",
    "    for i in n:\n",
    "        model = MLPRegressor(hidden_layer_sizes=(i*layers), max_iter=1000, random_state=1) #1000 iterations wasn't enough to optimize\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        scores = metrics.r2_score(y_test,y_pred)\n",
    "        scores1 = metrics.mean_squared_error(y_test,y_pred)\n",
    "        print(l,i,scores, scores1)\n",
    "        scores_list.append(metrics.r2_score(y_test,y_pred))\n",
    "        \n",
    "#printed results show layer, nodes, r^2, and MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
